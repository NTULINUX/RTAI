From 54656792509b1914636cae88684546ce8ee221bc Mon Sep 17 00:00:00 2001
From: Alec Ari <neotheuser@ymail.com>
Date: Thu, 20 Oct 2022 20:44:18 -0500
Subject: Convert to RTAI

Signed-off-by: Alec Ari <neotheuser@ymail.com>
---
 arch/x86/kernel/ipipe.c     |  6 ---
 include/ipipe/thread_info.h |  5 ++-
 kernel/ipipe/core.c         | 85 ++++++++++++-------------------------
 kernel/ipipe/timer.c        | 10 +++--
 kernel/sched/core.c         | 15 ++++++-
 5 files changed, 52 insertions(+), 69 deletions(-)

diff --git a/arch/x86/kernel/ipipe.c b/arch/x86/kernel/ipipe.c
index 300d5ee81..ad5e8ea83 100644
--- a/arch/x86/kernel/ipipe.c
+++ b/arch/x86/kernel/ipipe.c
@@ -263,15 +263,9 @@ EXPORT_SYMBOL_GPL(ipipe_set_irq_affinity);
 
 void ipipe_send_ipi(unsigned int ipi, cpumask_t cpumask)
 {
-	unsigned long flags;
-
-	flags = hard_local_irq_save();
-
 	cpumask_clear_cpu(ipipe_processor_id(), &cpumask);
 	if (likely(!cpumask_empty(&cpumask)))
 		apic->send_IPI_mask(&cpumask, ipipe_apic_irq_vector(ipi));
-
-	hard_local_irq_restore(flags);
 }
 EXPORT_SYMBOL_GPL(ipipe_send_ipi);
 
diff --git a/include/ipipe/thread_info.h b/include/ipipe/thread_info.h
index 7038c1294..bfda871d5 100644
--- a/include/ipipe/thread_info.h
+++ b/include/ipipe/thread_info.h
@@ -7,8 +7,11 @@
  */
 
 struct ipipe_threadinfo {
+	void *ptd[4];
 };
 
-#define __ipipe_init_threadinfo(__p) do { } while (0)
+static inline void __ipipe_init_threadinfo(struct ipipe_threadinfo *p) {
+	p->ptd[0] = p->ptd[1] = p->ptd[2] = p->ptd[3] = 0;
+}
 
 #endif /* !_IPIPE_THREAD_INFO_H */
diff --git a/kernel/ipipe/core.c b/kernel/ipipe/core.c
index 485db973b..085317c32 100644
--- a/kernel/ipipe/core.c
+++ b/kernel/ipipe/core.c
@@ -42,6 +42,20 @@
 #include <asm/syscall.h>
 #include <asm/unistd.h>
 
+EXPORT_SYMBOL(sys_call_table);
+int (*rtai_fastcall_hook)(struct pt_regs *) = NULL;
+EXPORT_SYMBOL(rtai_fastcall_hook);
+int (*rtai_syscall_hook)(struct pt_regs *) = NULL;
+EXPORT_SYMBOL(rtai_syscall_hook);
+int (*rtai_trap_hook)(int exception, struct pt_regs *) = NULL;
+EXPORT_SYMBOL(rtai_trap_hook);
+int (*rtai_kevent_hook)(int kevent, void *) = NULL;
+EXPORT_SYMBOL(rtai_kevent_hook);
+void (*rtai_migration_hook)(struct task_struct *) = NULL;
+EXPORT_SYMBOL(rtai_migration_hook);
+void (*dispatch_irq_head)(unsigned int) = NULL;
+EXPORT_SYMBOL(dispatch_irq_head);
+
 struct ipipe_domain ipipe_root;
 EXPORT_SYMBOL_GPL(ipipe_root);
 
@@ -1123,12 +1137,12 @@ EXPORT_SYMBOL_GPL(ipipe_set_hooks);
 
 int __weak ipipe_fastcall_hook(struct pt_regs *regs)
 {
-	return -1;	/* i.e. fall back to slow path. */
+	return rtai_fastcall_hook ? rtai_fastcall_hook(regs) : -1;
 }
 
-int __weak ipipe_syscall_hook(struct ipipe_domain *ipd, struct pt_regs *regs)
+int __ipipe_notify_syscall(struct pt_regs *regs)
 {
-	return 0;
+	return rtai_syscall_hook ? rtai_syscall_hook(regs) : 0;
 }
 
 static inline void sync_root_irqs(void)
@@ -1208,7 +1222,7 @@ int ipipe_handle_syscall(struct thread_info *ti,
 	return 0; /* pass syscall down to the host. */
 }
 
-int __ipipe_notify_syscall(struct pt_regs *regs)
+int __Ipipe_notify_syscall(struct pt_regs *regs)
 {
 	struct ipipe_domain *caller_domain, *this_domain, *ipd;
 	struct ipipe_percpu_domain_data *p;
@@ -1229,7 +1243,6 @@ int __ipipe_notify_syscall(struct pt_regs *regs)
 		__ipipe_set_current_context(p);
 		p->coflags |= __IPIPE_SYSCALL_R;
 		hard_local_irq_restore(flags);
-		ret = ipipe_syscall_hook(caller_domain, regs);
 		flags = hard_local_irq_save();
 		p->coflags &= ~__IPIPE_SYSCALL_R;
 		if (__ipipe_current_domain != ipd)
@@ -1259,12 +1272,12 @@ int __ipipe_notify_syscall(struct pt_regs *regs)
 	return ret;
 }
 
-int __weak ipipe_trap_hook(struct ipipe_trap_data *data)
+int __ipipe_notify_trap(int exception, struct pt_regs *regs)
 {
-	return 0;
+	return (!__ipipe_root_p && rtai_trap_hook) ? rtai_trap_hook(exception, regs) : 0;
 }
 
-int __ipipe_notify_trap(int exception, struct pt_regs *regs)
+int __Ipipe_notify_trap(int exception, struct pt_regs *regs)
 {
 	struct ipipe_percpu_domain_data *p;
 	struct ipipe_trap_data data;
@@ -1286,7 +1299,6 @@ int __ipipe_notify_trap(int exception, struct pt_regs *regs)
 		hard_local_irq_restore(flags);
 		data.exception = exception;
 		data.regs = regs;
-		ret = ipipe_trap_hook(&data);
 		flags = hard_local_irq_save();
 		p->coflags &= ~__IPIPE_TRAP_R;
 	}
@@ -1303,12 +1315,12 @@ int __ipipe_notify_user_intreturn(void)
 	return !ipipe_root_p;
 }
 
-int __weak ipipe_kevent_hook(int kevent, void *data)
+int __ipipe_notify_kevent(int kevent, void *data)
 {
-	return 0;
+	ipipe_root_only(); return rtai_kevent_hook ? rtai_kevent_hook(kevent, data) : 0;
 }
 
-int __ipipe_notify_kevent(int kevent, void *data)
+int __Ipipe_notify_kevent(int kevent, void *data)
 {
 	struct ipipe_percpu_domain_data *p;
 	unsigned long flags;
@@ -1322,7 +1334,6 @@ int __ipipe_notify_kevent(int kevent, void *data)
 	if (likely(p->coflags & __IPIPE_KEVENT_E)) {
 		p->coflags |= __IPIPE_KEVENT_R;
 		hard_local_irq_restore(flags);
-		ret = ipipe_kevent_hook(kevent, data);
 		flags = hard_local_irq_save();
 		p->coflags &= ~__IPIPE_KEVENT_R;
 	}
@@ -1332,8 +1343,10 @@ int __ipipe_notify_kevent(int kevent, void *data)
 	return ret;
 }
 
-void __weak ipipe_migration_hook(struct task_struct *p)
+void inline ipipe_migration_hook(struct task_struct *p)
 {
+	if (rtai_migration_hook)
+		rtai_migration_hook(p);
 }
 
 static void complete_domain_migration(void) /* hw IRQs off */
@@ -1410,49 +1423,6 @@ void __ipipe_notify_vm_preemption(void)
 }
 EXPORT_SYMBOL_GPL(__ipipe_notify_vm_preemption);
 
-static void dispatch_irq_head(unsigned int irq) /* hw interrupts off */
-{
-	struct ipipe_percpu_domain_data *p = ipipe_this_cpu_head_context(), *old;
-	struct ipipe_domain *head = p->domain;
-
-	if (unlikely(test_bit(IPIPE_STALL_FLAG, &p->status))) {
-		__ipipe_set_irq_pending(head, irq);
-		return;
-	}
-
-	/* Switch to the head domain if not current. */
-	old = __ipipe_current_context;
-	if (old != p)
-		__ipipe_set_current_context(p);
-
-	p->irqall[irq]++;
-	__set_bit(IPIPE_STALL_FLAG, &p->status);
-	barrier();
-	head->irqs[irq].handler(irq, head->irqs[irq].cookie);
-	__ipipe_run_irqtail(irq);
-	hard_local_irq_disable();
-	p = ipipe_this_cpu_head_context();
-	__clear_bit(IPIPE_STALL_FLAG, &p->status);
-
-	/* Are we still running in the head domain? */
-	if (likely(__ipipe_current_context == p)) {
-		/* Did we enter this code over the head domain? */
-		if (old->domain == head) {
-			/* Yes, do immediate synchronization. */
-			if (__ipipe_ipending_p(p))
-				__ipipe_sync_stage();
-			return;
-		}
-		__ipipe_set_current_context(ipipe_this_cpu_root_context());
-	}
-
-	/*
-	 * We must be running over the root domain, synchronize
-	 * the pipeline for high priority IRQs (slow path).
-	 */
-	__ipipe_do_sync_pipeline(head);
-}
-
 void __ipipe_dispatch_irq(unsigned int irq, int flags) /* hw interrupts off */
 {
 	struct ipipe_domain *ipd;
@@ -1737,6 +1707,7 @@ void __ipipe_do_sync_stage(void)
 
 	__clear_bit(IPIPE_STALL_FLAG, &p->status);
 }
+EXPORT_SYMBOL_GPL(__ipipe_do_sync_stage);
 
 void __ipipe_call_mayday(struct pt_regs *regs)
 {
diff --git a/kernel/ipipe/timer.c b/kernel/ipipe/timer.c
index 83b3c94d9..d223858ca 100644
--- a/kernel/ipipe/timer.c
+++ b/kernel/ipipe/timer.c
@@ -575,9 +575,6 @@ void ipipe_timer_set(unsigned long cdelay)
 	 * extra call to the tick handler would simply occur after 4
 	 * billions ticks.
 	 */
-	if (cdelay > UINT_MAX)
-		cdelay = UINT_MAX;
-
 	tdelay = cdelay;
 	if (t->c2t_integ != 1)
 		tdelay *= t->c2t_integ;
@@ -588,7 +585,7 @@ void ipipe_timer_set(unsigned long cdelay)
 	if (tdelay > t->max_delay_ticks)
 		tdelay = t->max_delay_ticks;
 
-	if (t->set(tdelay, t->timer_set) < 0)
+	t->set(tdelay, t->timer_set); return; if (t->set(tdelay, t->timer_set) < 0)
 		ipipe_raise_irq(t->irq);
 }
 EXPORT_SYMBOL_GPL(ipipe_timer_set);
@@ -654,3 +651,8 @@ void __ipipe_timer_refresh_freq(unsigned int hrclock_freq)
 					  t->host_timer->next_event, false);
 	}
 }
+
+EXPORT_SYMBOL(ipipe_select_timers);
+EXPORT_SYMBOL(ipipe_timers_release);
+EXPORT_SYMBOL(ipipe_timer_start);
+EXPORT_SYMBOL(ipipe_timer_stop);
diff --git a/kernel/sched/core.c b/kernel/sched/core.c
index e80f51059..5ebdb4db6 100644
--- a/kernel/sched/core.c
+++ b/kernel/sched/core.c
@@ -3438,10 +3438,22 @@ asmlinkage __visible void schedule_tail(struct task_struct *prev)
 /*
  * context_switch - switch to the new MM and the new thread's register state.
  */
-static __always_inline struct rq *
+struct rq *
 context_switch(struct rq *rq, struct task_struct *prev,
 	       struct task_struct *next, struct rq_flags *rf)
 {
+	if (likely(!rq)) {
+		struct mm_struct *mm, *oldmm;
+		mm = next->mm;
+		oldmm = prev->active_mm;
+		switch_mm_irqs_off(oldmm, next->active_mm, next);
+		if (!mm)
+			enter_lazy_tlb(oldmm, next);
+		smp_mb();
+		switch_to(prev, next, prev);
+		barrier();
+		return NULL;
+	}
 	prepare_task_switch(rq, prev, next);
 
 	/*
@@ -3498,6 +3510,7 @@ context_switch(struct rq *rq, struct task_struct *prev,
 
 	return finish_task_switch(prev);
 }
+EXPORT_SYMBOL(context_switch);
 
 /*
  * nr_running and nr_context_switches:
-- 
2.30.2

